# ğŸ™ï¸ audio_gpt con PyQT

**audio_gpt** es una aplicaciÃ³n discreta para **Windows 11** que captura el **audio interno del sistema** (como conferencias, vÃ­deos o llamadas), lo transcribe en segundo plano utilizando la **API Whisper de OpenAI**, y gestiona el flujo de trabajo mediante un sistema **productor-consumidor** basado en colas.

> âš ï¸ Este proyecto **solo funciona en Windows 11**, ya que depende de dispositivos de grabaciÃ³n internos como *Stereo Mix*.

---

## ğŸš€ CaracterÃ­sticas

- âœ… Captura el audio interno del sistema (no del micrÃ³fono).
- ğŸ§  Transcribe automÃ¡ticamente usando la API de Whisper (OpenAI).
- ğŸ” Usa un sistema **asÃ­ncrono de productor-consumidor** para grabar y procesar en paralelo.
- ğŸªŸ AplicaciÃ³n discreta, pensada para ejecutarse en segundo plano en Windows.
- ğŸ’¬ Transcripciones listas para ser usadas con modelos de lenguaje como GPT-4.

---

## ğŸ–¥ï¸ Requisitos

- Windows 11
- Python 3.9 o superior
- Acceso a la API de OpenAI con crÃ©ditos o plan activo
- Dispositivo de grabaciÃ³n tipo **Stereo Mix** (activado en el sistema)

---

## ğŸ“¦ InstalaciÃ³n

1. Clona el repositorio:

```bash
git clone https://github.com/tu-usuario/audio_gpt.git
cd audio_gpt
```

2. Crea y activa un entorno virtual:

```bash
python -m venv venv
venv\Scripts\activate
```

3. Instala las dependencias:

```bash
pip install -r requirements.txt
```

4. Crea un archivo `.env` con tu clave de OpenAI:

```env
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

---

## ğŸ§  Â¿CÃ³mo funciona?

El sistema se basa en dos componentes principales:

### ğŸ¤ Productor

- Graba fragmentos de audio del sistema cada `X` segundos.
- Coloca los fragmentos en una cola para ser transcritos.
- Funciona en segundo plano continuamente.

### ğŸ§¾ Consumidor

- Toma fragmentos de audio desde la cola.
- Llama a la **API de Whisper** de OpenAI.
- Devuelve texto limpio, listo para ser mostrado, almacenado o enviado a otro modelo (GPT, etc).

---

## ğŸ› ï¸ Uso

Lanza la aplicaciÃ³n principal:

```bash
python main.py
```

Puedes configurar la duraciÃ³n de grabaciÃ³n, modelo Whisper (`whisper-1`, etc.), y otros parÃ¡metros desde `config.py` o como variables de entorno.

---

## ğŸ“ Estructura del proyecto

```
audio_gpt/
â”œâ”€â”€ main.py                  # Arranque del sistema productor-consumidor
â”œâ”€â”€ audio_capture.py         # GrabaciÃ³n de audio del sistema
â”œâ”€â”€ transcriber.py           # ConexiÃ³n con la API de OpenAI (Whisper)
â”œâ”€â”€ queue_worker.py          # GestiÃ³n de la cola de tareas
â”œâ”€â”€ utils.py                 # Funciones auxiliares
â”œâ”€â”€ config.py                # ConfiguraciÃ³n del sistema
â”œâ”€â”€ .env                     # Tu clave API (no subir)
â”œâ”€â”€ requirements.txt         # Dependencias del proyecto
â””â”€â”€ README.md                # Este documento
```

---

## ğŸ§ª Ejemplo de resultado

TranscripciÃ³n generada desde un vÃ­deo de conferencia:

```
"Buenos dÃ­as a todos. Vamos a comenzar la presentaciÃ³n sobre inteligencia artificial aplicada a medicina..."
```

---

## ğŸ” Seguridad

- Usa `api_key.txt` para almacenar tu clave API de OpenAI de forma segura.
- AsegÃºrate de que `api_key.txt` estÃ© incluido en `.gitignore`!! Sino cualquiera tendrÃ¡ acceso a tu clave de OpenAI.
- Nunca subas tu clave a GitHub o compartas pÃºblicamente tu entorno.

---

## ğŸ§© Ideas futuras

- TranscripciÃ³n en tiempo real (streaming).
- ClasificaciÃ³n automÃ¡tica de fragmentos con GPT.
- ExportaciÃ³n de texto a TXT, DOCX o PDF.
- Interfaz grÃ¡fica opcional con PyQt para controlar grabaciÃ³n y procesamiento.

---

## ğŸ¤ Contribuciones

Â¡Pull requests y sugerencias son bienvenidas!  
Este proyecto estÃ¡ en desarrollo activo, asÃ­ que cualquier mejora, refactorizaciÃ³n o integraciÃ³n es bienvenida.

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la [MIT License](LICENSE).

---
